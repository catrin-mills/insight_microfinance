{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#=================\n",
    "# Import libraries\n",
    "#=================\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as plticker\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, logistic\n",
    "from sklearn.cross_validation import train_test_split, KFold\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, average_precision_score, precision_score, recall_score, accuracy_score\n",
    "#from sklearn.preprocessing import normalize\n",
    "import sklearn.preprocessing as preprocessing\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# from patsy import standardize\n",
    "# import timeit\n",
    "# script_start = timeit.default_timer()\n",
    "# import pylab as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#=================\n",
    "#User-edited fields\n",
    "#=================\n",
    "##--What features to train?  ##NOTE:  not showing all \n",
    "train_cols = ['usd_amount_l1', 'wkly_ins_due', 'on_time_payments_l1', 'max_paid_amt',\n",
    "               'max_paid_perc_l1', 'avg_msg_length_l1', 'tot_msg',\n",
    "               'usd_amount_l2', 'second_loan_per_increase', 'total_num_pmt_due', 'emi',\n",
    "               'loan_ratio', 'ins_20_bin_l1', 'ins_30_bin_l1', 'ins_40_bin_l1',\n",
    "                'ins_20_bin_late_l1', 'ins_30_bin_late_l1', 'ins_40_bin_late_l1',\n",
    "                'ins_20_bin_ontime_l1', 'ins_30_bin_ontime_l1', 'ins_40_bin_ontime_l1', 'on_time_perc_l1']\n",
    "\n",
    "##--filename(s)?\n",
    "#X data\n",
    "X_in = 'Xdata.csv' \n",
    "\n",
    "#y data\n",
    "y_in = 'ydata.csv' \n",
    "\n",
    "##--regularization type\n",
    "reg_method = 'l2'  ##CHANGE: to test more methods later\n",
    "\n",
    "##--class weight for data --> more ppl payoff than default \n",
    "classwgt = 'balanced'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#=================\n",
    "#Read in data\n",
    "#=================\n",
    "#--processed MySQL db using Python\n",
    "\n",
    "#--x data (loan features)\n",
    "Xdata = pd.read_csv(X_in) \n",
    "Xdata = Xdata.drop('Unnamed: 0', axis = 1)  ###clean this up in sqldata.py later!\n",
    "Xdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#--y data (succesffully repaid = 0, default = 1)\n",
    "ydata = pd.read_csv('ydata.20170212.001.csv')\n",
    "ydata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##--sanity CHECK\n",
    "null_data = Xdata[Xdata.isnull().any(axis=1)]\n",
    "null_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#+++++\n",
    "##--Grab fields you want\n",
    "##--not super clean way to do it, but can fix later! CHANGE\n",
    "#+++++\n",
    "X = Xdata\n",
    "\n",
    "y = ydata[['default']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#=================\n",
    "#Model\n",
    "#=================\n",
    "\n",
    "#+++++\n",
    "##--Train and test sets\n",
    "#+++++\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[train_cols], y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#+++++\n",
    "##--Scale data for model\n",
    "#+++++\n",
    "\n",
    "##standard scaler:  \"Standardize features by removing the mean and scaling to unit variance\" (from sklearn doc)\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test  = scaler.transform(X_test)\n",
    "\n",
    "##-sanity CHECK\n",
    "X_train.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##--training sets are no longer dfs, so convert them  ##CHANGE:  investigate to see if this is necessary!\n",
    "print(X_train.dtype)\n",
    "\n",
    "#-train\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_train.columns = train_cols\n",
    "X_train.columns\n",
    "\n",
    "#-test\n",
    "X_test = pd.DataFrame(X_test)\n",
    "X_test.columns = train_cols\n",
    "X_test.columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##--set indices to be same for X and y\n",
    "print(X_train.index)\n",
    "print(y_train.index)  ##DOUBLE CHECK why this is happening!\n",
    "\n",
    "y_train.index = X_train.iloc[:,0].index\n",
    "print(y_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##--quick look at training set\n",
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#+++++\n",
    "##--Logistic Regression MODEL\n",
    "#+++++\n",
    "logit = sm.Logit(y_train,X_train, class_weight = classwgt, method=reg_method) ##--since more pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##--fit to data\n",
    "result = logit.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result.summary()\n",
    "###key items:  coefficient\n",
    "###            p val  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#+++++\n",
    "##--get log odds from coefficients\n",
    "#+++++\n",
    "odd_rat = np.exp(result.params)\n",
    "print (odd_rat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#+++++\n",
    "##--marginal effects\n",
    "#+++++\n",
    "margeeff = result.get_margeff(method='dydx', at='mean')\n",
    "margeeff.summary()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:my_projects_env]",
   "language": "python",
   "name": "conda-env-my_projects_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
